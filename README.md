
# ü§ñ Autonomous Navigation Using Traditional and AI-Based Approaches

Welcome to the **Autonomous Navigation** project! This repository demonstrates and compares traditional and AI-enhanced navigation methods for robotic systems in simulated environments using **ROS Noetic** and **Gazebo**. üöÄ

---

## üìù Table of Contents
1. [Introduction](#introduction)
2. [Setup Instructions](#setup-instructions)
3. [Usage](#usage)
4. [Results](#results)
5. [Acknowledgements](#acknowledgements)
6. [Contributions](#contributions)

---

## üßê Introduction
This project explores two navigation paradigms:
- **Traditional Navigation**: Using SLAM and A* for pathfinding.
- **AI-Based Navigation**: Leveraging semantic segmentation with YOLOv8 to classify terrain into safe (green), challenging (yellow), and restricted (red) zones.

The **Jackal Robot** was employed in a simulated Gazebo environment, equipped with:
- üõ† **Sensors**: LiDAR, Intel RealSense D455, and IMU.
- üåê **Simulation Environment**: Clearpath Robotics' *Inspection World*.

![Placeholder for Gazebo Simulation Screenshot](#) <!-- Replace with actual image link -->

---

## üõ† Setup Instructions

### Prerequisites
Ensure the following are installed:
- ROS Noetic
- Gazebo
- RVIZ
- Python 3.9
- [Dependencies listed here](https://wiki.ros.org/ROS/Installation)

### Clone the Repository
```bash
git clone https://github.com/AdharshKan42/AI_Based_Auton_Nav
cd AI_Based_Auton_Nav
```

### Install Dependencies
```bash
rosdep update
rosdep install --from-paths src --ignore-src -r
```

### Build the Workspace
```bash
catkin_make
source devel/setup.bash
```

---

## üöÄ Usage

### 1Ô∏è‚É£ Launching the Simulation and Moving around
To start the **Gazebo** environment with the Jackal robot:
```bash
roslaunch cpr_inspection_gazebo inspection_world.launch platform:=jackal
```
#### Launching RVIZ
```bash
roslaunch jackal_viz view_robot.launch
```

#### To move the Bot around
```bash
rosrun teleop_twist_keyboard teleop_twist_keyboard.py cmd_vel:=/cmd_vel
```

#### To Launch the GUI Interface controller :
```bash
rosrun rqt_gui rqt_gui -s rqt_robot_steering
```

#### Camera Output
```bash
rosrun rqt_image_view rqt_image_view
```

### 2Ô∏è‚É£ Traditional Navigation Approach
#### Launching Gazebo
```bash
roslaunch cpr_inspection_gazebo inspection_world.launch platform:=jackal
```

#### Path Planning and Navigation (Launching gmapping with custom scan topic:)
```bash
roslaunch jackal_navigation gmapping_demo.launch scan_topic:=lidar/scan
```
```bash
roslaunch jackal_viz view_robot.launch config:=gmapping
```
#### Saving the map :
```bash
rosrun map_server map_saver -f mymap
```
#### To localize with AMCL :
```bash
roslaunch jackal_navigation amcl_demo.launch map_file:=/path/to/my/map.yaml
```

#### To start navigation :
```bash
roslaunch jackal_viz view_robot.launch config:=localization
```

#### Camera Output
- View camera: `rosrun rqt_image_view rqt_image_view`


### 3Ô∏è‚É£ AI-Based Navigation
Integrate the YOLOv8 model for real-time obstacle detection:
```bash
python ai_navigation_script.py  # Placeholder for the script
```

---

## üìä Results

| Metric                | Traditional (A*) | AI-Based (YOLOv8) |
|-----------------------|------------------|-------------------|
| Path Length (meters)  | 18.6            | 17.3             |
| Traversal Time (secs) | 45.2            | 39.8             |
| Collision Rate        | 1               | 0                |
| Computational Load    | 100% CPU        | 65% CPU, 30% GPU |
| Adaptability          | Low             | High             |

### Key Insights
- **Traditional Approach**: Reliable for static environments, struggles with dynamic changes.
- **AI-Based Approach**: Adapts well to unstructured terrains with efficient navigation.

![Placeholder for results graph](#) <!-- Replace with actual image link -->

---

## üôå Acknowledgements
- **Clearpath Robotics** for providing the simulation environment.
- **ROS Community** for robust tools and documentation.
- AI models powered by **YOLOv8**.

---

## ü§ù Contributions
This project was a collaborative effort by:
- Adharsh Kandula: Environment setup and AI model integration.
- Lohith Venkat Chamakura: Implementation of Traditional navigation algorithms.
- Nishit Popat: Mapping algorithms Pathfinding optimizations.
- Raghav Mathur: Testing of multiple models and finetuning.
- Wei Xiang: Data collection and preprocessing, AI model training and evaluation. 

---

**Feel free to contribute!** Submit issues or pull requests to improve this repository. üéâ

---

## üì∏ Image Placeholders
- **Simulation Environment**: ![Placeholder for simulation](#)
- **AI Inference Results**: ![Placeholder for inference results](#)
